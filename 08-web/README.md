### Before

 * Read Scott Murray's [tutorial on D3](http://alignedleft.com/tutorials/d3/).

Optional:

 * Install a JSON viewer for your browser, such as [JSONview](http://jsonview.com/).
 * Read this chapter from the Bad Data Handbook: "Data intended for human consumption, not machine consumption"


### Questions

 * What data formats have you worked with? What are their strengths and weaknesses?
 * How can you get data? What data would you like to get for your final project? Where could you get it? Where have you looked?
 * What other thoughts, comments, concerns, and questions do you have? What's on your mind?


### During

Application presentation.

Question review.

Play with basic [web scraping](scrape.py) using [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/).

```bash
pip install beautifulsoup
pip install lxml
pip install cssselect
```

[Slides](slides.pdf) on data and formats.

[API lab](lab_API.md) on getting data from the web.

Some intro and activity with [D3](http://d3js.org/).


### After

Optional:

 * Read Tom Levine's scraping wisdom:
     * [Websites to data tables](http://dada.pink/dada/web-sites-to-data-tables/)
	 * [Websites to data tables, in depth](http://dada.pink/dada/web-sites-to-data-tables-in-depth/)
 * `scrapy` is a Python package for doing web scraping with a little bit bigger framework. Check out their [tutorial](http://doc.scrapy.org/en/latest/intro/tutorial.html).
 * Check out [Crossfilter](http://square.github.io/crossfilter/), a
   fairly spectacular JavaScript library that lets you work with a lot
   of data in the browser and achieve neat interactive displays with
   scrubbing and so on. There's a nice
   [tutorial](http://blog.rusty.io/2012/09/17/crossfilter-tutorial/)
   that you might start with.
 * For more coding practice, you might check out one of [many coding competition sites/platforms](http://codecondo.com/coding-challenges).
